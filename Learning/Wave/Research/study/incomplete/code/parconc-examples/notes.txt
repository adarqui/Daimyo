source: http://chimera.labs.oreilly.com/books/1230000000929/

ch1: Introduction
-----------------

parallel program:
- one that uses a multiplicity of computational hardware to perform a computation more quickly.
- delegate different parts of the computation to different processors that execute at the same time
- concerned only with efficiency
- try to use a deterministic programming model
- deterministic parallel programming
- in haskell, most parallel programming models are deterministic
- always produces the same answer, regardless of how many processors are used to run it
- parallel programs can be debugged without actually running them in parallel

concurrency:
- program structuring technique in which there are multiple threads of control
- conceptually execute at the same time
- user sees their effects interleaved
- concerned with structuring a program that needs to interact with multiple independent external agents
- structuring technique for effectful code (IO monad in haskell)
- in the absence of concurrency: these programs have to be written with event loops and callbacks
- nondeterministic programming model
- concurrency sacrifices determinism
- "sometimes we want to parallelize programs that really do have side effects, then thee is no alternative but to use nondeterministic parallel or concurrent programming"

deterministic programming model:
- each program can give only one result

nondeterministic programming model:
- programs may have different results depending on some aspect of the execution

deterministic parallel programming:
- computer processors implement deterministic parallelism in the form of pipelining and multiple execution units

threadscope
- tool for visualizing the execution of haskell programs and is particularly useful for gaining insight into the behavior of parallel and concurrent haskell code



Part I: Parallel haskell
------------------------

biggest gains in performance are to be had by:
- using parallel techniques in our programs so as to make use of these extra cores

"age old problem":
- thwarts automatic parallelism
- to make the program faster, we have to gain more from parallelism than we lose due to the overhead of adding it
- compile time analysis cannot make good judgements in this area

parallel haskell programs are high level and declarative:
- do not explicitly deal with concepts like synchronization or communication

main thing that parallel haskell programmer has to think about is:
- partitioning - dividing up the problem into pieces that can be computed in parallel

partitioning issues:
- granularity
- data dependencies

granularity:
- if you make your tasks too small, the overhead of managing the tasks outweighs any benefit you might get from running them in parallel
- should be large enough to dwarf overhead, but not too large, because then you risk not having enough work to keep all processors busy

data dependencies:
- tasks that depend on each other must be performed sequentially


Ch2: Basic Parallelism: The Eval Monad
--------------------------------------

lazy language:
- expressions are not evaluated until they are required.

evaluated vs unevaluated expressions:
- unevaluated: let x = 1 + 2 :: Int
- ^^ thunk: 1 + 2
- evaluated: let x = 3 :: Int
- ^^ boxed integer: 3

ghci command: :sprint
- prints the value of an expression without causing it to be evaluated
- indicates unevaluated: _

seq:
- evaluates its first argument
- evaluates its arguments only as far as the first constructor (WHNF)
- ^^ seq evalutes its first argument to "weak head normal form" (WHNF)
- seq :: a -> b -> b
- shallow evaluation

normal form: fully evaluated
- use deepseq

deepseq:
- Control.DeepSeq
- deepseq :: NFData a => a -> b -> b
- evaluates the entire structure to WHNF
- deep evaluation

evaluate:
- evaluate :: a -> IO a
- like seq but in the IO monad
- evaluates argument to WHNF and returns it

thunks:
- defining an expression causes a thunk to be built representing that expression
- a thunk remains unevaluated until its value is required
- once evaluated, the thunk is replaced by its value

example of explicit thunks:

map :: (a -> b) -> [a] -> [b]
map f []     = []
map f (x:xs) = f x : map f xs

==

map :: (a -> b) -> [a] -> [b]
map f []     = []
map f (x:xs) = let
                   x'  = f x
                   xs' = map f xs
               in
                   x' : xs'


Control.Parallel.Strategies:
- Eval Monad, rpar, rseq

Strategies express deterministic parallelism: the result of the program is unaffected by evaluating in parallel. The parallel tasks evaluated by a Strategy may have no side effects. For non-deterministic parallel programming, see Control.Concurrent.

Strategies let you separate the description of the parallelism from the logic of your program, enabling modular parallelism. The basic idea is to build a lazy data structure representing the computation, and then write a Strategy that describes how to traverse the data structure and evaluate components of it sequentially or in parallel.

Strategies are compositional: larger strategies can be built by gluing together smaller ones.

Monad and Applicative instances are provided, for quickly building strategies that involve traversing structures in a regular way.

Eval Monad:
- rpar combinator:
    - creates parallelism.
    - "my argument could be evaluated in parallel."
    - argument should be an unevaluated thunk
- rseq combinator:
    - forces sequential evaluation.
    - "evaluate my argument and wait for the result."
- runEval:
    - performs the Eval computation
    - completely pure
    - no IO here
- evaluation is to WHNF


rpar example:
- returns immediately

  runEval $ do
     a <- rpar (f x)
     b <- rseq (f y)
     return (a,b)


rpar/rseq example:
- waits for (f y) to complete before returning


rpar/rseq/rseq example:
- returns after both f y AND f x are complete

 runEval $ do
     a <- rpar (f x)
     b <- rseq (f y)
     rseq a
     return (a,b)


rpar/rpar/rseq/rseq:
- the longest
- more symmetry

runEval $ do
     a <- rpar (f x)
     b <- rpar (f y)
     rseq a
     rseq b
     return (a,b)


force:
- defined in Control.DeepSeq
- force :: NFData a => a -> a
- evaluates the entire structure of its argument, reducing it to normal form

Speedups are always calculated as a ratio of:
- wall-clock times.

important principle when parallelizing code:
- Try to avoid partitioning the work into a small, fixed number of chunks.
- chunks rarely contain an equal amount of work
- parallelism is limited to the number of chunks
- can call rpar as many times as we want
- ghc will automatically distribute the work among available cores

static partitioning:
- fixed division of work

dynamic partitioning:
- distributing smaller units of work among processors at runtime
- already provided by ghc
- can automatically scale to the number of processors

spark:
- argument to rpar
- runtime collects sparks in a pool
- uses them when there are spare processors available
- known as work stealing
- very cheap to create: basically a pointer to an expression in an array
- can be:
    - converted
    - overflowed: spark pool has fixed size, overflow happens when pool is full
    - dud: when rpar is applied to an expression that is already evaluated
    - gc'd: spark expression was unused, runtime removes it
    - fizzled: unevaluated at the time it was sparked but later evaluated independently by the program

parMap:
- creates sparks for each element in the list
- evaluation of all the results can happen in parallel


amdahl's law:
- gives maximum speedup as a ratio
- parallel speedup becomes harder to achieve as more processors are added in
- most programs have a theoretical maximum amount of parallelism
1 / ((1 - P) + P/N)
P: portion of the runtime that can be parallelized 
N: number of processors available


NFData
- class
- normal-form data
- 'normal-form' is a value with no unevaluated subexpressions
- 'data' means only data can be put into normal form, not functions

class NFData a where
  rnf :: a -> ()
  rnf a = a `seq` ()
- rnf: reduce to normal form: fully evaluates its argument and then returns ()
    - default to use seq
- recursively apply rnf to the component of a data type

"length evaluates only the spine of a list"
- lists cells but not the elements in those cells


Ch3: Evaluation Strategies
--------------------------
