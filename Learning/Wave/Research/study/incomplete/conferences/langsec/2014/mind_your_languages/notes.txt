no common understanding about the notion of intrinsic security of languages

"a secure software is expected to be able to cope with wilful aggressions by intelligent agents"

functional specification:
- ie, uncompress (compress (f)) = f
- typically describes what is needed by the system user as well as requested properties of inputs and outputs (e.g. of the software system).
- says nothing about the behavior when applied to arbitrary inputs
- would like to see specification for resilience

NQ:
"The tools we are trying to use and the language or notation we are trying to express or record our thoughts, are the major factors determining what we can think or express at all"
-- Dijkstra

mechanisms that blur expectations are likely to translate to security concerns
- "crossing frontiers"

variable scoping:
- scope: local vs global
- life cycle: constant, variable, volatile

example scoping issue where $var is overwritten:
    $var = "Hello World ";
    $tab = array("Foo ", "Bar ", "Blah ");
    { foreach ($tab as $var) { printf($var); } }
    printf($var);
- if programmer assumes $var is scoped to the foreach, bug

side effects:
- converse to lambda calc, in the presence of side effects, the order of computations may become observable.

typed lambda calculus:
- a pure functional language
- evaluation strategy has no influence on the result of computations

example of evaluation order ambiguity:
- C, right to left evaluation
- if this code is discouraged by C standards, why then does it compile without even a warning?
{ int c=0; printf("%d %d\n",c++,c++); }     -> 1 0
{ int c=0; printf("%d %d\n",++c,++c); }     -> 2 2
{ int c=0; printf("%d %d\n",(c=1),(c=2)); } -> 1 1

"affectations are by definition the primitive form of side-effect

anything revealing the evaluation strategy can be considered:
- a side effect

IMP:
Pretty straightforward, so what do the following pieces of
code (without even playing with macros)?
    int zero(int x) { return 0; }
    int main(void) { int x=0; x=zero(1/x); return 0; }
Code snippet 10.
    int zero(int x) { return 0; }
    int main(void) { int x=0; return zero(1/x); }
Code snippet 11.
There is unfortunately no simple answer to this simple question:
using the GCC compiler, there is an exception for both
with option -O0, with option -O1 the first code returns 0 and
with option -O2 the second also returns 0.

in C, standard optimizations can modify the observable behavior of a program

ocaml variables:
- live in the heap
- prevent storing constants in read only pages
- even worse, all strings are mutable

ocaml string mutability security issue example:
- second alert false will return "T"
- alert modified by a side effect
let alert = function true -> "T" | false -> "F";;
(alert false).[0]<-’T’;;
alert false;;


types
-----

type theory:
- can statically reject syntactically valid but meaningless expressions
- enforce encapsulation
- manage genericity or polymorphism
- leads to type inference and static verification
- does not contradict developers' intuition
- IMP: a must for secure developments; preferably both static and strong

casts, coercions and overloading:
- automatic overloading and type casts are evil
- false friends, too devious to be managed properly
- weaken detection of ill-formed expressions
- the compiler is basically authorized to manipulate the code until it has meaning
- regarding devs using casts: "none of them actually know what's going on"

NQ:
"All animals are equal, but some animals are more equal than others."

a lack of strict types can be seen in the following erlang factorial example:
    -module(factorial).
    -compile(export_all).
    fact(0) -> 1;
    fact(N) -> N*fact(N-1).
- factorial:fact(4) returns 24
- factorial:fact(4.0) overflows

equality is expected to be transitive:
- javascript breaks this: '0'==0, and 0=='0.0' are true. However: '0'=='0.0' is false.
- transitive property: if a = b and b = c, then a = c

compile options:
- for example, C's -Wconversion alerts you of unsafe conversions

php's auto conversions of strings into hex/scientific notation can be very dangerous
- "0xf9" == "249e0"

insane:
-  When compared with == they are therefore all converted into the same value, that is float(0).
$h1=md5("QNKCDZO");
$h2=md5("240610708");
$h3=md5("A169818202");
$h4=md5("aaaaaaaaaaaumdozb");
$h5=sha1("badthingsrealmlavznik");
if ($h1==$h2) print("Collision\n");
if ($h2==$h3) print("Collision\n");
if ($h3==$h4) print("Collision\n");
if ($h4==$h5) print("Collision\n");


type abstraction:
- can lead to oversimplistic analyses in some cases


#!/bin/bash
PIN_CODE=1234
echo -n "4-digits PIN code for authentication: "
read -s INPUT_CODE; echo
if [ "$PIN_CODE" -ne "$INPUT_CODE" ]; then
echo "Invalid PIN code"; exit 1
else
echo "Authentication OK"; exit 0
fi


types at runtime in static type-checking systems:
- pure logical info that have no concrete existence in implementations


evaluators:
- dynamically modify or create code
- allows for metaprogramming and other dynamic features
- any form of evaluator makes a program impossible to analyse
- language embedded evaluators forbid security evaluation
- allow for code injection
- blur the frontier between data, metadata, and code
- ie, php: eval, $$x, $x()

consistency:
- identical keywords in different languages can have different semantics
- in some cases, same keyword can have different semantics dependent on how it is used

confusion:
- x = 1 returns a number
- x == 1 returns a boolean (which is a number)
- linux trojan attempt

nuts:
(* x" enable security checks *)
let x’’=true;;
(* REMOVED ON Friday 13th 2013 ===============
(* x"=false to disable checks during tests *)
let x’’=false;;
(* Set x"=true once tests are completed *)
CHANGED x" TO ENABLE SECURITY CHECKS =========*)

let x''=true;; is actually commented out.. let x''=false;; isn't commented..


what really matters from the evaluation perspective?
- behavior of the program at runtime

To illustrate the genericity of this notion, let us consider
the shell: what would you expect as the result of the command
rm * in a directory containing a file named -fr, for example?e

interpreted language:
- with JIT compilers, modern interpreted languages need memory to be writable and executable at runtime, preventing the use of W ^ X mechanisms.

undefined behavior

encapsulation and compilation

memory protections in native binaries
- critical parts of a system could benefit from finger-grain memory protections

garbage collection:
- very hard (or even impossible) to control lifetime of a secret data in the presence of a garbage collector
- free'd areas are generally not cleared, for performance reasons
- mark-and-copy GC's might also spread secrets several times across the memory

optimizations:
- optimizations can remove code that clears out strings etc

NQ:
"Software and cathedrals are very much the same - first we build them, then we pray."
-- Sam Redwine

security certification:
- relies on analyses of the program and of its development process by independent evaluators, a process known as security evaluation.

developing an adequate level of mastery of the constructs of a language requires both:
- practice an theory

specifications:
- partial specifications or ambiguous specifications lead to bugs
- non deterministic specs can be tricky to handle
- prefer languages to be specified completely, explicitly and formally as possible
- avoid non deterministic or partial properties

code signing:
- useful for low-level libraries

When the evaluation process includes a source code audit,
a good knowledge of the involved programming languages can
help the evaluators, but we believe it is more important that
they have a deep understanding of the features provided by
the language and used by the developers. For example, objectoriented
paradigm and serialization mechanisms are pervasive.
The potential security issues are the same across programming
languages implementing them. We have also discussed the very
generic concept of code injection.

refinement paradox:

development vs production builds:
- can have differences, ie, due to optimization etc

language design:
- language principles, whatever their theoretical elegance, must never go against developers' (or evaluators') intuition
- eliminate non-determinism in the specification of a language, and make explicit as far as possible undefined behaviors (if any)
- always balance the advantages of new constructions with the added complexicity for developers to master their semantics.

robustness principle: (Postel's law)
- states that you should be conservative in what you do and liberal in what you accept.
- aims at improving interoperability
- not appropriate when security is at stake

each developer should be security literate.

functional approaches: checking that what should work, works
dual approaches: checking that what should not happen, never happens
- worst-case reasonings related to unsatisfied pre-conditions, out-of-range values, ill-formed messages

devs have to learn the basics in several domains:
- language semantics
- compilation theory
- operating system principles
- computer architecture

